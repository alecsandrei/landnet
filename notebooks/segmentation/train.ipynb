{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f50c0a96-0d78-44d7-8bb4-2ff3330e77ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "ARCHITECTURE = 'unet'\n",
    "os.environ['ARCHITECTURE'] = ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a69cce2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from landnet.modelling.segmentation.models import (\n",
    "    DeepLabV3ResNet50Builder,\n",
    "    FCNResNet50Builder,\n",
    "    UNetBuilder,\n",
    ")\n",
    "from pathlib import Path\n",
    "from landnet.enums import GeomorphometricalVariable, Mode\n",
    "from landnet.features.tiles import TileConfig, TileSize\n",
    "from landnet.features.grids import get_grid_for_variable\n",
    "import torch\n",
    "from landnet.modelling.segmentation.lightning import (\n",
    "    LandslideImageSegmenter,\n",
    "    LandslideImageSegmentationDataModule,\n",
    ")\n",
    "from landnet.modelling.dataset import (\n",
    "    get_default_mask_transform,\n",
    "    get_default_transform,\n",
    "    get_default_augment_transform,\n",
    ")\n",
    "from landnet.modelling.tune import MetricSorter\n",
    "from landnet.modelling.segmentation.dataset import (\n",
    "    ConcatLandslideImageSegmentation,\n",
    "    LandslideImageSegmentation,\n",
    ")\n",
    "from landnet.modelling.segmentation.inference import Infer\n",
    "from landnet.modelling import torch_clear\n",
    "import lightning as L\n",
    "from landnet.typing import TuneSpace\n",
    "import typing as t\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "torch_clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5429464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "    GeomorphometricalVariable('shade'),\n",
    "    GeomorphometricalVariable('tpi'),\n",
    "    GeomorphometricalVariable('dem'),\n",
    "    GeomorphometricalVariable('nego'),\n",
    "    GeomorphometricalVariable('tri'),\n",
    "    GeomorphometricalVariable('eastness'),\n",
    "    GeomorphometricalVariable('clo'),\n",
    "    GeomorphometricalVariable('area'),\n",
    "    GeomorphometricalVariable('slope'),\n",
    "    GeomorphometricalVariable('croto'),\n",
    "]\n",
    "train_tile_config = TileConfig(TileSize(100, 100), overlap=0)\n",
    "train_model_config: TuneSpace = {\n",
    "    'batch_size': 4,\n",
    "    'learning_rate': 0.000001,\n",
    "    'tile_config': train_tile_config,\n",
    "}\n",
    "\n",
    "test_tile_config = TileConfig(TileSize(100, 100), overlap=0)\n",
    "test_model_config: TuneSpace = {\n",
    "    'batch_size': 4,\n",
    "    'tile_config': test_tile_config,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ea725b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/miniforge3/envs/landnet/lib/python3.12/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_grids = [\n",
    "    get_grid_for_variable(\n",
    "        variable,\n",
    "        tile_config=train_tile_config,\n",
    "        mode=Mode.TRAIN,\n",
    "    )\n",
    "    for variable in variables\n",
    "]\n",
    "\n",
    "validation_grids = [\n",
    "    get_grid_for_variable(\n",
    "        variable,\n",
    "        tile_config=test_tile_config,\n",
    "        mode=Mode.VALIDATION,\n",
    "    )\n",
    "    for variable in variables\n",
    "]\n",
    "\n",
    "train_dataset = ConcatLandslideImageSegmentation(\n",
    "    landslide_images=[\n",
    "        LandslideImageSegmentation(\n",
    "            grid,\n",
    "            Mode.TRAIN,\n",
    "            transform=get_default_transform(),\n",
    "            mask_transform=get_default_mask_transform(),\n",
    "        )\n",
    "        for grid in train_grids\n",
    "    ],\n",
    "    augment_transform=get_default_augment_transform(),\n",
    "    # augment_transform=None,\n",
    ")\n",
    "\n",
    "validation_dataset = ConcatLandslideImageSegmentation(\n",
    "    landslide_images=[\n",
    "        LandslideImageSegmentation(\n",
    "            grid,\n",
    "            Mode.VALIDATION,\n",
    "            transform=get_default_transform(),\n",
    "            mask_transform=get_default_mask_transform(),\n",
    "        )\n",
    "        for grid in validation_grids\n",
    "    ],\n",
    "    augment_transform=None,\n",
    ")\n",
    "\n",
    "# train_dataset, validation_dataset = torch.utils.data.random_split(\n",
    "#     dataset, (0.7, 0.3)\n",
    "# )\n",
    "# t.cast(\n",
    "#     ConcatLandslideImageSegmentation, train_dataset\n",
    "# ).augment_transform = get_default_augment_transform()\n",
    "\n",
    "test_grids = [\n",
    "    get_grid_for_variable(\n",
    "        variable,\n",
    "        tile_config=test_tile_config,\n",
    "        mode=Mode.TEST,\n",
    "    )\n",
    "    for variable in variables\n",
    "]\n",
    "test_dataset = ConcatLandslideImageSegmentation(\n",
    "    landslide_images=[\n",
    "        LandslideImageSegmentation(\n",
    "            grid,\n",
    "            Mode.TEST,\n",
    "            transform=get_default_transform(),\n",
    "            mask_transform=get_default_mask_transform(),\n",
    "        )\n",
    "        for grid in test_grids\n",
    "    ],\n",
    "    augment_transform=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "095aa2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "model = UNetBuilder(len(variables), 2).build(\n",
    "    in_channels=len(variables), mode=Mode.TRAIN\n",
    ")\n",
    "dm = LandslideImageSegmentationDataModule(\n",
    "    train_model_config,\n",
    "    variables,\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    validation_dataset=validation_dataset,\n",
    ")\n",
    "segmenter = LandslideImageSegmenter(train_model_config, model, 2)\n",
    "trainer = L.Trainer(\n",
    "    enable_checkpointing=True,\n",
    "    callbacks=[EarlyStopping(monitor='val_mIoU', mode='max', patience=5)],\n",
    "    max_epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351ee987",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO: \n",
      "  | Name            | Type                         | Params | Mode \n",
      "-------------------------------------------------------------------------\n",
      "0 | model           | Unet                         | 51.5 M | train\n",
      "1 | criterion       | CrossEntropyLoss             | 0      | train\n",
      "2 | train_metrics   | SegmentationMetricCollection | 0      | train\n",
      "3 | val_metrics     | SegmentationMetricCollection | 0      | train\n",
      "4 | test_metrics    | SegmentationMetricCollection | 0      | train\n",
      "5 | predict_metrics | SegmentationMetricCollection | 0      | train\n",
      "-------------------------------------------------------------------------\n",
      "51.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "51.5 M    Total params\n",
      "206.141   Total estimated model params size (MB)\n",
      "376       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f64fb307a5c4bab8bf3f990a3e6e8cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = trainer.fit(model=segmenter, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be3bb7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d8d72f3dd74249ba6fb5b0c73ccb6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">            Test metric            </span>┃<span style=\"font-weight: bold\">           DataLoader 0            </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_dice_score_epoch       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        0.5503259897232056         </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test_generalized_dice_score_epoch </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        0.4524320363998413         </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_loss_epoch          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        0.6645846366882324         </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_mIoU_epoch          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        0.3366027772426605         </span>│\n",
       "└───────────────────────────────────┴───────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m           Test metric           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m          DataLoader 0           \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_dice_score_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.5503259897232056        \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtest_generalized_dice_score_epoch\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.4524320363998413        \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_loss_epoch         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.6645846366882324        \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_mIoU_epoch         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.3366027772426605        \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────────────┴───────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_dice_score_epoch': 0.5503259897232056,\n",
       "  'test_generalized_dice_score_epoch': 0.4524320363998413,\n",
       "  'test_mIoU_epoch': 0.3366027772426605,\n",
       "  'test_loss_epoch': 0.6645846366882324}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model=segmenter, dataloaders=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781e102b-3800-44df-8eac-c92cb9031f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77c07cc81c743568f341e825415cb62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9dfc43896d54a7f9bd2b848666bbc07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d84077140cc464a8c9f53b2999e2a0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "infer = Infer(variables, test_model_config)\n",
    "parent = Path(\n",
    "    '/media/alex/alex/python-modules-packages-utils/landnet/notebooks/lightning_logs'\n",
    ")\n",
    "last_version = sorted(\n",
    "    map(lambda x: int(x.name.split('_')[-1]), parent.glob('version*'))\n",
    ")[-1]\n",
    "last_version = '16'\n",
    "ckpt = Path(\n",
    "    f'/media/alex/alex/python-modules-packages-utils/landnet/notebooks/lightning_logs/version_251/checkpoints/epoch=37-step=4750.ckpt'\n",
    ")\n",
    "infer.handle_checkpoint(\n",
    "    ckpt,\n",
    "    model=UNetBuilder(len(variables), 2).build(\n",
    "        in_channels=len(variables), mode=Mode.TRAIN\n",
    "    ),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "landnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
